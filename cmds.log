   17  cut -f 8 PRODUCTS/0439139597.20221019_021514.txt |awk '{total += $1; count++} END {print total/count}' >> avg.txt
   18  cut -f 8 PRODUCTS/0439139597.20221019_021514.txt >> a.txt
   19  head s.txt
   20  awk -F "\t" 'BEGIN{sum=0; count=0}{sum=sum+$8; count=count+1}END{print sum/count}' 0439139597.20221019_021514.txt
   21  awk -F "\t" 'BEGIN{sum=0; count=0}{sum=sum+$8; count=count+1}END{print sum/count}' 0439139597.LATEST.txt >> 0439139597.AVGRATING.txt
   22  crontab -e
   23  ls
   24  history
   25  exit
   26  git init
   27  mkdir ws6
   28  cp amazon_reviews_us_Books_v1_02.tsv ws6
   29  cd ws6/
   30  ls
   31  rm -rf cron.log
   32  ls
   33  vi worksheet6.sh
   34  ls
   35  crontab-l
   36  crontab -l
   37  cd PRODUCTS
   38  mkdir PRODUCTS
   39  fgrep "0439139597" amazon_reviews_us_Books_v1_02.tsv > PRODUCTS/0439139597.txt
   40  cd PRODUCTS/
   41  ls
   42  cp /home/shamika/ws6/PRODUCTS/0439139597.txt /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.TXT
   43  mv /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.TXT /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.txt
   44  ls
   45  echo $DATETIME
   46  vi worksheet6.sh
   47  ls
   48  history
   49  exit
   50  mkdir ws6
   51  cp amazon_reviews_us_Books_v1_02.tsv ws6
   52  cd ws6
   53  mkdir PRODUCTS
   54  fgrep "04391139597" amazon_reviews_us_Books_v1_02.tsv > PRODUCTS/04391139597.txt
   55  DATETIME=$(date +%Y%m%d_%H%M%S)
   56  cd PRODUCTS
   57  ls
   58  cp /home/shamika/ws6/PRODUCTS/04391139597.txt /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt
   59  ls
   60  ln -s /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt home/shamika/ws6/PRODUCTS/04391139597.LATEST.txt
   61  cd
   62  cd ws6
   63  ln -s /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt home/shamika/ws6/PRODUCTS/04391139597.LATEST.txt
   64  vi worsksheet6.sh
   65  ls
   66  cat cron.log
   67  crontab -e
   68  history > cmds.log
   69  history
   70  git init
   71  script WS6.txt
   72  git add WS6.txt
   73  ls
   74  cd ws6
   75  ls
   76  cp cmds.log ~
   77  cd
   78  ls
   79  git add cmds.log
   80  git branch -M main
   81  git commit -m "first commit"
   82  git remote add origin https://github.com/shamikamm/ws6.git
   83  git remove remote origin
   84  git rm remote origin
   85  git remote remove origin
   86  git remote add origin https://github.com/shamikamm/ws6.git
   87  git push -u origin main
   88  gti rm --cashed ws4.txt
   89  git rm --cashed ws4.txt
   90  git rm --cached ws4.txt
   91  git commit -m "ws4 removed"
   92  git push origin
   93  git rm --cached ws3.txt
   94  git commit -m "ws3 removed"
   95  git push origin
   96  git rm --cached a1.txt
   97  git commit -m "a1 removed"
   98  git push origin
   99  git rm --cached A2.txt
  100  git commit -m "A2 removed"
  101  git push origin
  102  git rm --cached README
  103  git commit -m "README removed"
  104  git push origin
  105  git rm --cached ws4_1.txt
  106  git commit -m "ws4_1 removed"
  107  git push origin
  108  git rm --cached ws5.txt
  109  git commit -m "ws5 removed"
  110  git push origin
  111  cd
  112  ls
  113  cd A3/
  114  ls
  115  rm A3.svg
  116  ls
  117  head P2,txt
  118  cat P2.txt
  119  cut -f 1 P2.txt
  120  awk -F "\t" '{print $1} P2.txt > p2_1.txt
  121  awk -F "\t" '{print $1}' P2.txt > p2_1.txt
  122  ls
  123  cat p2_1.txt
  124  exit
  125  ls
  126  cd A3/
  127  ls
  128  exit
  129  ls
  130  cd A3/
  131  ls
  132  display histogram.svg
  133  exit
  134  ls
  135  cd A3
  136  ls
  137  head p2_1.txt
  138  /etc/gnuplot-5.4.4/src/gnuplot
  139  ls
  140  awk -F "\t" '{print $1}' P2.txt > c.txt
  141  ls
  142  rm P2_1.txt
  143  rm -f p2_1.txt
  144  ls
  145  head c.txt
  146  rm -f c.txt
  147  ls
  148  cur -f 1 -d ' ' P2.txt > c.txt
  149  ls
  150  head c.txt
  151  head P2.txt
  152  ls
  153  rm c.txt
  154  ls
  155  cut -f 1 -d ' ' P2.txt > d.txt
  156  ls
  157  head d.txt
  158  cut -f 2 -d ' ' P2.txt > e.txt
  159  ls
  160  rm d.txt
  161  ls
  162  head e.txt
  163  cut -f 5 ' ' P2.txt > f.txt
  164  cut -5 5 -d ' ' P2.txt > f.txt
  165  cut -5 -d ' ' P2.txt > f.txt
  166  cut -f 5 -d ' ' P2.txt > f.txt
  167  ls
  168  rm e.txt
  169  ls
  170  head f.txt
  171  cut -f 4 -d ' ' P2.txt > s.txt
  172  rm f.txt
  173  head s.txt
  174  rm s.txt
  175  ls
  176  sed 's/\t/,/g'  P2.txt > P2_1.txt
  177  ls
  178  head P2_1.txt
  179  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k1n |awk -F "\t"'{if($1>=3){print}}' >> P2_2.txt
  180   awk -F "\t" '{print $1}' directional_graph.txt > s.txt
  181  sort s.txt |uniq -c |sort -k1n |head
  182  sort s.txt |uniq -c |sort -k1n |awk -F "\t"'{if($1>=3){print}}' |head
  183  sort s.txt |uniq -c |sort -k1n > t.txt
  184  ls
  185  cd a3/
  186  cd A3/
  187  ls
  188  wc -l P2.txt
  189  ls
  190  cd A3/
  191  ls
  192  rm s.txt
  193  rm -f t.txt
  194  rm -f a3.xterm
  195  ls
  196  rm P2_1.txt
  197  rm P2_2.txt
  198  ls
  199  tail P2.txt
  200  tail replied_to.txt
  201  ls
  202  tail directional_graph.txt
  203  wc -c directional_graph.txt |sort -k 1 -n
  204  wc -c P2.txt |sort -k 1 -n
  205  sort directional_graph.txt |sort -k -n
  206  sort directional_graph.txt |sort -k 1 -n
  207  clear
  208  ls
  209  head directional_graph.txt
  210  cut -f 1 directional_graph.txt |head
  211  awk -F "\t" '{print $6}' replited_to.txt > m.txt
  212  awk -F "\t" '{print $6}' replied_to.txt > m.txt
  213  ls
  214  wc -c m.txt
  215  cd A3/
  216  ls
  217  /etc/gnuplot-5.4.4/src/gnuplot
  218  ls
  219  cd A3/
  220  display file.svg
  221  cd A3/
  222  ls
  223  display file.svg
  224  display histogram.svg
  225  ls
  226  cd A3/
  227  ls
  228  /etc/gnuplot-5.4.4/src/gnuplot
  229  tail P2.txt
  230  /etc/gnuplot-5.4.4/src/gnuplot
  231  wc -l P2.txt
  232  /etc/gnuplot-5.4.4/src/gnuplot
  233  ls -latr
  234  rm histogram.svg
  235  rm file.svg
  236  ls
  237  wc -l m.txt
  238  wc -l P2.txt
  239  /etc/gnuplot-5.4.4/src/gnuplot
  240  cat P2.txt
  241  /etc/gnuplot-5.4.4/src/gnuplot
  242  sort P2.txt |uniq -c|sort -n > P2_1.txt
  243  ls
  244  cat P2_1.txt
  245  /etc/gnuplot-5.4.4/src/gnuplot
  246  ls
  247  rm file.svg
  248  ls
  249  rm m.txt
  250  ls
  251  tail reply_cluster.txt
  252  awk '{if($1!=$2){print}}' reply_cluster.txt > no_bot.txt
  253  ls
  254  tail no_bot.txt
  255  head replied_to.txt
  256  awk '{if($6!=$2){print}}' replied_to.txt >> p.txt
  257  ls
  258  head p.txt
  259  awk -F "\t" '{print $6, $2}' p.txt > q.txt
  260  head q.txt
  261  cat q.txt
  262  rm p.txt
  263  rm q.txt
  264  ls
  265  rm no_bot.txt
  266  ;s
  267  ls
  268  rm p2_1.txt
  269  exit
  270  ls
  271  cd A3/
  272  ls
  273  display histogram.svg
  274  rm histogram.svg
  275  ls
  276  cd A3/
  277  ls
  278  cat P2_1.txt
  279  awk -F "\t" '{if($6!=$2){print}}' replied_to.txt > s.txt
  280  head s.txt
  281  awk -F "\t" '{print $6,$2}' s.txt > z.txt
  282  sort -k 1 -n z.txt > y.txt
  283  cat y.txt
  284  awk "\t"'{if($1>=3){print}}' y.txt > P2_2.txt
  285  awk -F "\t" '{if($1>=3){print}}' y.txt > P2_2.txt
  286  cat P2_2.txt
  287  awk '{if($1>=3){print}}' y.txt > P2_3.txt
  288  head p2_3.txt
  289  head P2_3.txt
  290  tail P2_3.txt
  291  wc -l P2_3.txt
  292  cut -f 1 P2_3.txt |head
  293  cut -f 1 -d ' ' P2_3.txt |tail
  294  sort P2_3.txt |sort -k 1 -n > l.txt
  295  cat l.txt
  296  rm l.txt
  297  sort P2_3.txt |sort -k 1 -n |uniq -c
  298  cut -f 1 -d ' ' P2_3.txt > p.txt
  299  head p.txt
  300  tail p.txt
  301  awk '{if($1>=3){print}}' p.txt > q.txt
  302  cat q.txt
  303  wc -l q.txt
  304  ls
  305  rm z.txt
  306  rm y.txt
  307  rm p.txt
  308  rm q.txt
  309  ls
  310  rm s.txt
  311  rm P2_2.txt
  312  ls
  313  rm P2_1.txt
  314  ls
  315  head directional_graph.txt
  316  cut -f 1 -d ' ' directional_graph.txt |tail
  317  cut -f 1 -d ' ' directional_graph.txt |uniq -c |sort -k 1 -n |awk 'if($1>=3){print}}' > z.txt
  318  cut -f 1 -d ' ' directional_graph.txt |uniq -c |sort -k 1 -n > z.txt
  319  cat z.txt
  320  awk 'if($1>=3){print}}' q.txt > r.txt
  321   awk '{if($1>=3){print}}' q.txt > r.txt
  322  awk '{if($1>=3){print}}' z.txt > r.txt
  323  cat r.txt
  324  /etc/gnuplot-5.4.4/src/gnuplot
  325  ls
  326  history
  327  git init
  328  scruot A3.txt
  329  mkdir A3
  330  ls
  331  cp downloaded_tweets_extend_original_nolf2.tsv A3
  332  cp downloaded_tweets_extend_nolf2.tsv A3
  333  cd A3/
  334  ls
  335  head downloaded_tweets_extend_original_nolf2.tsv
  336  grep "replied_to" downloaded_tweets_extend_original_nolf2.tsv > replied_to.txt
  337  awk -F "\t" '{print $6, $2}' replied_to.txt |sort -n > directional_graph.txt
  338  ls
  339  head directional_graph.txt
  340  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k 1 -n > reply_cluster.txt
  341  ls
  342  awk '{if($1>=3){print}}' reply_cluster.txt > problem_2.txt
  343  ls
  344  head problem_2.txt
  345  tail problem_2.txt
  346  /etc/gnuplot-5.4.4/src/gnuplot
  347  cd A3/
  348  ls
  349  cd
  350  ls
  351  exit
  352  ls
  353  rm -rf A3/
  354  ls
  355  /mnt/scratch/shamika
  356  ls
  357  cd /mny/scratch/shamika
  358  cd /mnt/scratch/shamika
  359  ls
  360  mkdir ws7
  361  ls
  362  cp amazon_reviews_us_Books_v1_02.tsv ws7
  363  cd
  364  mkdir ws7
  365  cp amazon_reviews_us_Books_v1_02.tsv ws7
  366  cd ws7/
  367  ls
  368  head amazon_reviews_us_Books_v1_02.tsv
  369  grep "0373836635" amazon_reviews_us_Books_v1_02.tsv > file.txt
  370  ls
  371  cat file.txt
  372  awk -F "\t" '{print $14}' > 0373836635.txt
  373  cut -f 14 -d ' ' file.txt > 0373836635.txt
  374  ls
  375  0373836635.txt
  376  cat 0373836635.txt
  377  rm 0373836635.txt
  378  awk -F "\t" '{print $14}' file.txt > 0373836635.txt
  379  ls
  380  cat 0373836635.txt
  381  sed -e 's/,/\t/' 0373836635.txt -e 's/;/\t/' 0373836635.txt -e 's/and/\t/' 0373836635.txt -e 's/or\t/' 0373836635.txt -e 's/if\t/' 0373836635.txt -e 's/if\t/' 0373836635.txt -e 's/in\t/' 0373836635.txt -e 's/it\t/' 0373836635.txt -e 0373836635.txt > new_0373836635.txt
  382  sed -e 's/,/\t/' 0373836635.txt -e 's/;/\t/' 0373836635.txt -e 's/and/\t/' 0373836635.txt -e 's/or/\t/' 0373836635.txt -e 's/if/\t/' 0373836635.txt -e 's/in/\t/' 0373836635.txt -e 's/it/\t/' 0373836635.txt > new_0373836635.txt
  383  cat new_0373836635.txt
  384  sed -e 's/<[br]>/\t/' new_0373836635.txt > output.txt
  385  ls
  386  cat output.txt
  387  sed 's/<[br /]+>//g ; /^$/d' output.txt
  388  sed 's/<[^>]*>//g ; /^$/d'
  389  sed 's/<[^>]*>//g ; /^$/d' output.txt
  390  history
  391  exit
  392  mkdir ws7
  393  git init
  394  cp amazon_reviews_us_Books_v1_02.tsv ws7
  395  cd ws7/
  396  ls
  397  pwd
  398  head amazon_reviews_us_Books_v1_02.tsv
  399  grep "0373836635" amazon_reviews_us_Books_v1_02.tsv > product.txt
  400  ls
  401  cat products.txt
  402  cat product.txt
  403  awk -F "\t" '{print $14}' product.txt > 0373836635.txt
  404  ls
  405  cat 0373836635.txt
  406  vi commands.txt
  407  ls
  408  sed -f commands.txt 0373836635.txt > output.txt
  409  vi commands.txt
  410  sed -f commands.txt 0373836635.txt > output.txt
  411  cat commands.txt
  412  vi commands.txt
  413  sed -f commands.txt 0373836635.txt > output.txt
  414  ls
  415  rm -rf commands.txt
  416  ls
  417  sed 's/,/\t/' 0373836635.txt > no_commas.txt
  418  sed 's/;/\t/' no_commas.txt > no_semicolon.txt
  419  sed 's/and//g' no_semicolon.txt > no_and.txt
  420  sed 's/if//g' no_and.txt > no_in.txt
  421  sed 's/or//g' no_in.txt > no_or.txt
  422  sed 's/in//g' no_or.txt > no_if.txt
  423  sed 's/it//g' no_if.txt > no_it.txt
  424  sed 's/<[^>]*>//g ; /^$/d' no_it.txt > final_output.txt
  425  ls
  426  cat final_output.txt
  427  history>cmds.log
  428  ls
  429  history
  430  tmux new-session -s homework 
  431  script ws7.txt
  432  cd ws7/
  433  cd
  434  ls
  435  rm -rf cmds.log
  436  ls
  437  cd ws7/
  438  ls
  439  cp cmds.log ~
  440  cd
  441  git add ws7.txt
  442  git add cmds.log
  443  git branch -M main
  444  git commit -m "first commit"
  445  git remote add origin https://github.com/shamikamm/ws7.git
  446  git remote remove origin
  447  git remote add origin https://github.com/shamikamm/ws7.git
  448  git push -u origin main
  449  exit
  450  mkdir a4
  451  ls
  452  cp downloaded_tweets_extend_nolf2.tsv a4
  453  cp downloaded_tweets_extend_original_nolf2.tsv a4
  454  cd a4/
  455  ls
  456  pwd
  457  grep retweeted downloaded_tweets_extend_nolf2.tsv |awl -F "\t" '{print $5}' |sed 's/^.* id=//g' |sed 's/ type=retweeted.//g' > retweeted.txt
  458  grep retweeted downloaded_tweets_extend_nolf2.tsv |awk  -F "\t" '{print $5}' |sed 's/^.* id=//g' |sed 's/ type=retweeted.//g' > retweeted.txt
  459  ls
  460  head retweeted.txt
  461   for i in cat retweets2.txt; do  grep -E "^$i" downloaded_tweets_extend_original_nolf2.tsv | awk '{print $2}' ; done > userids_retweets4.txt
  462  ls
  463  sort userids_retweets4.txt | uniq -c | sort -n  | tail
  464  ls
  465  cat  userids_retweets4.txt
  466  rm  userids_retweets4.txt
  467  ls
  468  for i in cat `retweeted.txt`; grep -E "^$i" downloaded_tweets_extend_original_nolf2.tsv | awk '{print $2}' ; done > user_id,txt
  469  for i in cat `retweeted.txt`; do grep -E "^$i" downloaded_tweets_extend_original_nolf2.tsv | awk '{print $2}' ; done > user_id.txt
  470  ls
  471  for i in cat retweeted.txt;do grep -E "^$i" downloaded_tweets_extend_original_nolf2.tsv | awk '{print $2}' ; done > user_id.txt
  472  ls
  473  head user_id.txt
  474  cat user_id.txt
  475  for i in cat 'retweeted.txt' ; do grep -E "^$i" downloaded_tweets_extend_original_nolf2.tsv | awk '{print $2}' ; done > user_id.txt
  476  cat user_id.txt
  477  rm user_id.txt
  478  ls
  479  cat retweeted.txt
  480  ls
  481  sort retweeted.txt |uniq -c |sort -n > retweeted_1.txt
  482  wc retweeted_1.txt
  483  fgrep -f retweeted_1.txt downloaded_tweets_extend_original_nolf2.tsv |awk '{print$2}' >user_id.txt
  484  sort user_id/txt |uniq -c |sort -n
  485  sort user_id.txt |uniq -c |sort -n
  486  head retweeted_1.txt
  487  fgrep -f retweeted_1.txt downloaded_tweets_extend_original_nolf2.tsv |awk -F "\t" '{print $2}' > users_id.txt
  488  ls
  489  head users_id.txt
  490  rm user_id.txt, users_id.txt
  491  rm user_id.txt
  492  rm users_id.txt
  493  ls
  494  rm retweeted_1.txt
  495   fgrep -f `retweeted.txt` downloaded_tweets_extend_original_nolf2.tsv |awk -F "\t" '{print $2}' > users_id.txt
  496  ls
  497  grep -f `retweeted.txt` downloaded_tweets_extend_original_nolf2.tsv |awk -F "\t" '{print $2}' > users_id.txt
  498  ls
  499  cat users_id.txt
  500  rm users_id.txt
  501  for i in cat retweeted.txt; do grep -E "^$1" downloaded_tweets_extend_original_nolf2.tsv |awk '{print $2}'; done > users.txt
  502  cat user.txt
  503  cat users.txt
  504  sort users.txt |uniq -c |sort -n |tail
  505  awk -F "\t" '{print $5, $2}' > incluence_users.txt
  506  awk -F "\t" '{print $5, $2}' retweeted.txt > r.txt
  507  cat r.txt
  508  ls
  509  head downloaded_tweets_extend_nolf2.tsv
  510  grep retweeted downloaded_tweets_extend_nolf2.tsv re.txt
  511  clear
  512  ls
  513  exit
  514  history
  515  git init
  516  git branch
  517  tmux new session -s hw
  518  1;2c
  519  tmux new session -s homework
  520  script a4.txt
  521  ls
  522  rm a4.txt
  523  ls
  524  cd a4/
  525  ls
  526  hrad r.txt
  527  head r.txt
  528  rm r.txt
  529  ls
  530  grep retweeted downloaded_tweets_extend__nolf2.tsv
  531  head downloaded_tweets_extend_nolf2.tsv
  532  grep retweeted downloaded_tweets_extend_nolf2.tsv > ret.txt
  533  head ret.txt
  534  awk -F “\t” ‘{print $5, $2}’ |sort -n > dierctional_graph.txt
  535  awk -F "\t" '{print $5, $2}' ret.txt |sort -n > directional_graph.txt
  536  ls
  537  head directional_graph.txt 
  538  tail directional_graph.txt 
  539  awk -F “\t” ‘{print $1}’ directional_graph.txt |uniq -c |sort k1n > reply_cluster.txt
  540  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort k1n > reply_cluster.txt
  541  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k 1 -n > reply_cluster.txt
  542  cd
  543  ls
  544  rm -rf cmds.log
  545  rm ws4
  546  rm -rf ws4
  547  rm -rf ws3
  548  ls
  549  rm -rf A1
  550  rm -rf a2
  551  ls
  552  cd a4/
  553  ls
  554  head incluence_users.txt
  555  rm incluence_users.txt 
  556  ld
  557  l
  558  sls
  559  ls
  560  head users.txt
  561  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k 1 -n > reply_cluster.txt
  562  ls
  563  head reply_cluster.txt
  564  awk '{if ($1>=$3){print}}' reply_cluster.txt > cluster_threshold.txt
  565  ls
  566  head cluster_threshold.txt 
  567  cat cluster_threshold.txt 
  568  rm cluster_threshold.txt 
  569  ls
  570  for i in reply_cluster.txt; do awk '{if($i>=3){print}}'; done > threshold_replies.txt
  571  ls
  572  ls
  573  cd a4/
  574  ls
  575  cat threshold_replies.txt 
  576  rm threshold_replies.txt 
  577  ls
  578  sed 's/ type=retweeted.//g' threshold_replies.txt |sed 's/^.* id=//g' > new_tr.txt
  579  cat threshold_replies.txt
  580  sed 's/ type=retweeted.//g' reply_cluster.txt |sed 's/^.* id=//g' > new_rc.txt
  581  head new_rc.txt
  582  head rephead reply_cluster.txt 
  583  cut -f 1 -d ' ' new_rec.txt
  584  cut -f 1 -d ' ' new_rc.txt
  585  clear
  586  ls
  587  cut -f 2 -d ' ' new_rc.txt > new_rc_2.txt 
  588  ls
  589  rm new_tr.txt
  590  ls
  591  tail new_rc_2.txt
  592  head new_rc_2.txt
  593  awk '{if($1>=$3){print}}' new_rc_2.txt > threshold.txt
  594  cat threshold.txt
  595  ls
  596  cd
  597  ls
  598  cd a4
  599  ls
  600  head new_rc.txt
  601  awk -F "\t" '{if($1>=3){print}}' new_rc.txt > l.txt
  602  head l.txt
  603  sort -k 1 l.txt |sort -n > m.txt
  604  head m.txt
  605  wc -l l.txt
  606  cat l.txt
  607  wc -l m.txt
  608  wc -l new_rc.txt
  609  awk -F "\t" '{if($1>=3){print}}' new_rc.txt
  610  cat m.txt
  611  rm m.txt
  612  ls
  613  rm l.txt
  614  ls
  615  head new_rc_2.txt
  616  awk -F "\t" '{if($1>=3){print}}' new_rc_2.txt > p.txt
  617  wc -l p.txt
  618  head directional_graph.txt
  619  awk -F "\t" '{if($1>=3){print}}' directional_graph.txt > b.txt
  620  wc -l directional_graph.txt 
  621  head b.txt
  622  wc -l b.txt
  623  cd a4/
  624  cd a4/
  625  ls
  626  head b.txt
  627  cat b.txt
  628  grep 400190499585544192 b.txt
  629  grep 1520474822697914368
  630  grep 1520474822697914368 b.txt
  631  grep 1520389150561734658 b.txt
  632  grep 1520139548679933955 b.txt
  633  grep 1520139548679933955 retweeted.txt
  634  grep 1261203450022359043 b.txt
  635  ls
  636  rm b.txt
  637  head new_rc_2.txt
  638  rm new_rc_2.txt
  639  rm new_rc.txt
  640  rm p.txt
  641  ls
  642  cat directional_graph.txt
  643  rm directional_graph.txt
  644  ls
  645  rm directional_graph.txt
  646  rm dierctional_graph.txt
  647  ls
  648  rm reply_cluster.txt
  649  ls
  650  rm threshold.txt
  651  ls
  652  head ret.txt
  653  awk -F "\t" '{print $2, $5}' ret.txt > directional_graph.txt
  654  ls
  655  head directional_graph.txt
  656  sort directional_graph.txt |uniq -c |sort -k 1 -n > reply_cluster.txt
  657  head reply_cluster.txt 
  658  awk '{if(($1>=3){print}}' reply_cluster.txt > threshold.txt
  659  awk '{if($1>=3){print}}' reply_cluster.txt > threshold.txt
  660  cat threshold.txt 
  661  tail threshold.txt 
  662  cat threshold.txt 
  663  sort -n threshold.txt 
  664  ls
  665  sort directional_graph.txt |uniq -c |sort -n |tail
  666   sort directional_graph.txt |uniq -c |sort -n |head
  667  cut -f 1 -d ' ' directional_graph.txt > a.txt
  668  head a.txt
  669  awk '{if($1>=3){print}}' a.txt > t.txt
  670  cat t.txt
  671  cd /mnt/scratch/shamika
  672  ls
  673  pwd
  674  ls
  675  cd /mnt/scratch/shamika
  676  ls
  677  cd ws8/
  678  ls
  679  grep "Y\t" file.txt > verified.txt
  680  ls
  681  head verified.txt 
  682  head amazon_reviews_us_Books_v1_02.tsv 
  683  quit
  684  exit
  685  pwd
  686  ls
  687  r ws8
  688  mkdir ws8
  689  ls
  690  /mnt/scratch/shamika
  691  cd /mnt/scratch/shamika: Is a directory
  692  cp amazon_reviews_us_Books_v1_02.tsv /mnt/scratch/shamika
  693  ls
  694  cd /mnt/scratch/shamika
  695  ls
  696  cd ws7
  697  ls
  698  rmdir ws7
  699  rm -rf ws7
  700  ls
  701  cd
  702  ls
  703  cd /mnt/scratch/shamika
  704  ls
  705  rm -rf ws7
  706  ls
  707  mkdir ws8
  708  ls
  709  cp amazon_reviews_us_Books_v1_02.tsv ws8
  710  cd ws8/
  711  ls
  712  cd /mnt/scratch/shamika
  713  ls
  714  cd ws8/
  715  ls
  716  head amazon_reviews_us_Books_v1_02.tsv 
  717  cd /mnt/scratch/shamika/
  718  ls
  719  cd ws8/
  720  ls
  721  pwd
  722  awk -F "\t" '{print $12, $14}' amazon_reviews_us_Books_v1_02.tsv > file.txt
  723  cut -f 12, 14 -d ' ' amazon_reviews_us_Books_v1_02.tsv > file.txt
  724  awk -F "\t" '{print $12, $14}' amazon_reviews_us_Books_v1_02.tsv > file.txt
  725  ls
  726  head file.txt
  727  grep "Y" file.txt > verified.txt
  728  ls
  729  head verified.txt
  730  wc verified.txt
  731  wc file.txt
  732  cd /mnt/scratch/shamika
  733  ls
  734  cd ws8
  735  ls
  736  pwd
  737  tail verified.txt
  738  rm -f verified.txt 
  739  ls
  740  ls
  741  cd /mnt/scratch/shamika
  742  cd ws8/
  743  pwd
  744  ls
  745  grep -P "\tY\t" file.txt > verified.txt
  746  ls
  747  head verified.txt 
  748  cat verified.txt 
  749  rm verified.txt 
  750  ls
  751  grep -P '\tY\tY\t' amazon_reviews_us_Books_v1_02.tsv > f.txt
  752  ls
  753  head f.txt
  754  head amazon_reviews_us_Books_v1_02.tsv 
  755  ls
  756  /mnt/scratch/shamika
  757  ls
  758  cd /mnt/scratch/shamika
  759  ls
  760  cd ws8/
  761  pwd
  762  ls
  763  head f.txt
  764  rm -f f.txt
  765  ls
  766  rm -f verified.txt 
  767  ls
  768  grep "Y" amazon_reviews_us_Books_v1_02.tsv |awk -F "\t" '{print $12, $14}' > file_1.txt
  769  grep -P "\tY\tY\t" amazon_reviews_us_Books_v1_02.tsv > a.txt
  770  ls
  771  head a.txt
  772  awk -F "\t" '{print $12,$14}' a.txt > verified.txt
  773  ls
  774  head verified.txt 
  775  tail verified.txt 
  776  wc verified.txt 
  777  cat verified.txt 
  778  grep "\tY\t" amazon_reviews_us_Books_v1_02.tsv > v.txt
  779  ls
  780  head v.txt
  781  cat v.txt
  782  rm v.txt
  783  ls
  784  grep "tN\tY\t" amazon_reviews_us_Books_v1_02.tsv |awk -F "\t" '{print $12,$14} > file_2.txt
  785  grep "tN\tY\t" amazon_reviews_us_Books_v1_02.tsv |awk -F "\t" '{print $12,$14}' > file_2.txt
  786  ls
  787  head file_2.txt
  788  grep "tN\tY\t" amazon_reviews_us_Books_v1_02.tsv >b.txt
  789  head b.txt
  790  grep "\tY\tN\t" amazon_reviews_us_Books_v1_02.tsv >c.txt
  791  head c.txt
  792  grep exit
  793  cd /mnt/scratch/shamika
  794  ls
  795  cd ws8/
  796  ls
  797  head a.txt
  798  rm a.txt
  799  rm b.txt
  800  rm c.txt
  801  head verified.txt
  802  caat verified.txt 
  803  cst verified.txt 
  804  cat verified.txt 
  805  wc -l verified.txt 
  806  rm verified.txt 
  807  ls
  808  head file_1.txt 
  809  rm file_1.txt 
  810  rm file_2.txt 
  811  rm file.txt 
  812  ls
  813  clear
  814  ls
  815  head amazon_reviews_us_Books_v1_02.tsv 
  816  cut -f 12 -d ' ' amazon_reviews_us_Books_v1_02.tsv > file.txt
  817  ls
  818  head file.txt 
  819  wc fiel
  820  wc file.txt 
  821  tail file.txt 
  822  rm file.txt 
  823  cut -f 11 -d ' ' amazon_reviews_us_Books_v1_02.tsv > f.txt
  824  head f.txt
  825  rm f.txt
  826  cut -f 13 -d ' ' amazon_reviews_us_Books_v1_02.tsv |head
  827  tail amazon_reviews_us_Books_v1_02.tsv 
  828  cut -f 12 -d ' ' amazon_reviews_us_Books_v1_02.tsv |tail
  829  cut -f 10 -d ' ' amazon_reviews_us_Books_v1_02.tsv |head
  830  cut -f 12 amazon_reviews_us_Books_v1_02.tsv |head
  831  cut -f 12 amazon_reviews_us_Books_v1_02.tsv > file.txt
  832  wc -l file.txt 
  833  wc -l amazon_reviews_us_Books_v1_02.tsv 
  834  head file.txt 
  835  tail file.txt 
  836  rm file.txt
  837  ls
  838  cut -f 12,14 amazon_reviews_us_Books_v1_02.tsv > file.txt
  839  ls
  840  head file.txt 
  841  grep Y file.txt > verified.txt
  842  ls
  843  head verified.txt 
  844  rm verified.txt 
  845  grep "Y\t" file.txt > verified.txt
  846  ls
  847  head verified.txt 
  848  rm verified.txt 
  849  ls
  850  cd /mnt/scratch/shamika
  851  ls
  852  cd ws8/
  853  ls
  854  head file.txt
  855  cut -1 file.txt |head
  856  cut -f 1 file.txt |head
  857  for i in file.txt; do awk '{if ($1=Y) {print}}'; done > verified.txt
  858  awk '{if ($1=Y) {print}}' file.txt > verified.txt
  859  ls
  860  head verified.txt 
  861   awk '{if ($1=Y) {print}}' file.txt
  862  awk '{if ($1='Y'){print}}' file.txt
  863  cd /mnt/scratch/shamika
  864  ls
  865  cd ws8/
  866  ls
  867  head verified.txt 
  868  rm verified.txt 
  869  ls
  870  head file.txt
  871  grep "N" file.txt > unverified.txt
  872  ls
  873  head unverified.txt 
  874  wc unverified.txt 
  875   grep -P '\tY\tY\t' amazon_reviews_us_Books_v1_02.tsv |awk -F "\t" '{print $14}' > verified.txt
  876  ls
  877  rm unverified.txt 
  878  ls
  879  head verified.txt 
  880  rm verified.txt 
  881  ls
  882   grep -P '\tY\tY\t' amazon_reviews_us_Books_v1_02.tsv |awk -F "\t" '{print $12,$14}' > verified.txt
  883  ls
  884  head verified.txt 
  885  ls
  886  wc verified.txt 
  887  awk -F "\t" '{print $12,$14}' amazon_reviews_us_Books_v1_02.tsv > col.txt
  888  cut -f 12,14 amazon_reviews_us_Books_v1_02.tsv > col.txt
  889  ls
  890  rm verified.txt 
  891  ls
  892  head col.txt 
  893  cat col.txt 
  894  cd /mnt/scratch/shamika
  895  ls
  896  sed -n 'books/p' amazon_reviews_us_Books_v1_02.tsv 
  897  sed -n 'books/ p' amazon_reviews_us_Books_v1_02.tsv 
  898  exit
  899  cd /mnt/scratch/shamika
  900  chmod 700
  901  chmod --help
  902  chmod 700 /mnt/scratch/shamika
  903  ks
  904  ls
  905  exit
  906  cd /mnt/scratch/shamika
  907  ls
  908  cd ws8/
  909  ls
  910  head file.txt 
  911  if $1=Y; print >verified.txt
  912  cd /mnt/scratch/shamika
  913  cd ws8/
  914  pwd
  915  ls
  916  head col.txt 
  917  wc -l file.txt 
  918  wc -l col.txt 
  919  rm col.txt 
  920  ls
  921  grep -P '\tY\tY\t' amazon_reviews_us_Books_v1_02.tsv > yes.txt
  922  ls
  923  head yes.txt 
  924  cut -f 12 yes.txt > p.txt
  925  head yes.txt 
  926  tail yes.txt 
  927  grep -P '\tN\tY\t' amazon_reviews_us_Books_v1_02.tsv > yes.txt
  928  ls
  929  head yes.txt 
  930  tail yes.txt 
  931  awk -F "\t" '{print $12, $14}' > verified .txt
  932  awk -F "\t" '{print $12, $14}' yes.txt > verified.txt
  933  rm -f p.txt
  934  ls
  935  rm verified
  936  ls
  937  head verified.txt 
  938  cd /mnt/scratch/shamika
  939  ls
  940  cd ws8/
  941  ls
  942  head verified.txt 
  943  cut -f 1 verified.txt |head 
  944  cut -f 1 -d ' ' verified.txt |head
  945  cut -f 1 -d ' ' verified.txt |tail
  946  wc -l verified.txt 
  947  ls
  948  rm file.txt
  949  ls
  950  gerp -P '\tN\tN\t' amazon_reviews_us_Books_v1_02.tsv > no.txt
  951  grep -P '\tN\tN\t' amazon_reviews_us_Books_v1_02.tsv > no.txt
  952  grep -P '\tY\tN\t' amazon_reviews_us_Books_v1_02.tsv > no.txt
  953  ls 
  954  head no.txt 
  955  awk -F "\t" '{print $12, $14}' no.txt > unverified.txt
  956  ls
  957  head unverified.txt 
  958  cut -f 1 -d ' ' unverified.txt 
  959  wc -l unverified.txt 
  960  wc -l no.txt 
  961  rm no.txt 
  962  rm unverified.txt 
  963  ls
  964  wc -l amazon_reviews_us_Books_v1_02.tsv 
  965  wc -l verified.txt 
  966  grep -P '\tN\tN\t' amazon_reviews_us_Books_v1_02.tsv | wc
  967  grep -P '\tY\tN\t' amazon_reviews_us_Books_v1_02.tsv | wc
  968  grep -P '\tN\tN\t' amazon_reviews_us_Books_v1_02.tsv >no.txt
  969  ls
  970  head no.txt 
  971  awk -F "\t" '{print $12, $14}' no.txt > unverified.txt
  972  ls
  973  cut -f 1 -d ' ' unverified.txt |head
  974  wc -l unverified.txt 
  975  wc -l verified.txt 
  976  wc -l amazon_reviews_us_Books_v1_02.tsv 
  977  fgrep -v -w -f /usr/share/groff/current/eign verified.txt 
  978  ls
  979  rm no.txt 
  980  rm yes.txt 
  981  ls
  982  sed -E 's/(is |and |if |it |the |or |is |as |a |to |that |there |this)/\t/g' verified.txt > ver.txt
  983  head ver.txt
  984  sed -E 's/(is |and |if |it |the |or |is |as |a |to |that |there |this)/\t/g' unverified.txt > unver.txt
  985  head unver.txt
  986  sort ver.txt | uniq -c |sort -k1,1nr -k2b > com_vertxt
  987  head com_vertxt 
  988  rm com_vertxt 
  989  ls
  990  tr -c '[:alnum:]' '[\n*]' < ver.txt | fgrep -v -w -f /usr/share/groff/current/eign | sort | uniq -c | sort -nr | head  -10
  991   tr -c '[:alnum:]' '[\n*]' < ver.txt |sort | uniq -c | sort -nr | head  -10
  992  quit
  993  exit
  994  /mnt/scratch/shamika
  995  cd /mnt/scratch/shamika
  996  ls
  997  rm -rf ws8
  998  ls
  999  xit
 1000  exit
 1001  git init
 1002  mkdir ws8
 1003  cp amazon_reviews_us_Books_v1_02.tsv ws8
 1004  cd ws8/
 1005  ls
 1006  pwd
 1007  grep -P "\tN\tY\t' amazon_reviews_us_Books_v1_02.tsv > y.txt
 1008   grep -P "\tN\tY\t" amazon_reviews_us_Books_v1_02.tsv > y.txt
 1009  /mnt/scratch/shamika
 1010  script ws8.txt
 1011  exit
 1012  history
 1013  script WS8.txt
 1014  cd /mnt/scratch/shamika
 1015  script Ws8.txt
 1016  history > cmds.log
